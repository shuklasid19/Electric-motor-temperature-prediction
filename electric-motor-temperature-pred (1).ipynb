{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-09T18:45:39.095466Z","iopub.execute_input":"2022-05-09T18:45:39.095991Z","iopub.status.idle":"2022-05-09T18:45:39.111368Z","shell.execute_reply.started":"2022-05-09T18:45:39.095960Z","shell.execute_reply":"2022-05-09T18:45:39.110429Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.model_selection import KFold\nfrom sklearn import linear_model\nfrom sklearn.metrics import make_scorer\nfrom sklearn import svm\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\nfrom sklearn import neighbors\nfrom math import sqrt\nfrom sklearn.metrics import r2_score,mean_squared_error\n\n#import the metrics \nfrom sklearn import metrics\n\nfrom sklearn.preprocessing import scale \nfrom sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.decomposition import PCA\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:45:39.130096Z","iopub.execute_input":"2022-05-09T18:45:39.130334Z","iopub.status.idle":"2022-05-09T18:45:40.304293Z","shell.execute_reply.started":"2022-05-09T18:45:39.130306Z","shell.execute_reply":"2022-05-09T18:45:40.303555Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"The data set comprises several sensor data collected from a permanent magnet synchronous motor (PMSM) deployed on a test bench. The PMSM represents a german OEM's prototype model. Test bench measurements were collected by the LEA department at Paderborn University.","metadata":{}},{"cell_type":"markdown","source":"# Content\nAll recordings are sampled at 2 Hz. The data set consists of multiple measurement sessions, which can be distinguished from each other by column \"profile_id\". A measurement session can be between one and six hours long.\n\nThe motor is excited by hand-designed driving cycles denoting a reference motor speed and a reference torque.\nCurrents in d/q-coordinates (columns \"id\" and iq\") and voltages in d/q-coordinates (columns \"ud\" and \"uq\") are a result of a standard control strategy trying to follow the reference speed and torque.\nColumns \"motor_speed\" and \"torque\" are the resulting quantities achieved by that strategy, derived from set currents and voltages.\n\nMost driving cycles denote random walks in the speed-torque-plane in order to imitate real world driving cycles to a more accurate degree than constant excitations and ramp-ups and -downs would.","metadata":{}},{"cell_type":"code","source":"#i\ndf = pd.read_csv('/kaggle/input/electric-motor-temperature/measures_v2.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:45:40.306006Z","iopub.execute_input":"2022-05-09T18:45:40.306271Z","iopub.status.idle":"2022-05-09T18:45:47.354552Z","shell.execute_reply.started":"2022-05-09T18:45:40.306234Z","shell.execute_reply":"2022-05-09T18:45:47.353987Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:45:47.355617Z","iopub.execute_input":"2022-05-09T18:45:47.356480Z","iopub.status.idle":"2022-05-09T18:45:47.366571Z","shell.execute_reply.started":"2022-05-09T18:45:47.356439Z","shell.execute_reply":"2022-05-09T18:45:47.365499Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:45:47.370003Z","iopub.execute_input":"2022-05-09T18:45:47.370331Z","iopub.status.idle":"2022-05-09T18:45:47.401695Z","shell.execute_reply.started":"2022-05-09T18:45:47.370295Z","shell.execute_reply":"2022-05-09T18:45:47.400785Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:45:47.402872Z","iopub.execute_input":"2022-05-09T18:45:47.403281Z","iopub.status.idle":"2022-05-09T18:45:47.446536Z","shell.execute_reply.started":"2022-05-09T18:45:47.403249Z","shell.execute_reply":"2022-05-09T18:45:47.445561Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:45:47.447733Z","iopub.execute_input":"2022-05-09T18:45:47.447937Z","iopub.status.idle":"2022-05-09T18:45:47.804623Z","shell.execute_reply.started":"2022-05-09T18:45:47.447910Z","shell.execute_reply":"2022-05-09T18:45:47.803826Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:45:47.806004Z","iopub.execute_input":"2022-05-09T18:45:47.806199Z","iopub.status.idle":"2022-05-09T18:45:47.832988Z","shell.execute_reply.started":"2022-05-09T18:45:47.806172Z","shell.execute_reply":"2022-05-09T18:45:47.832162Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df.dtypes.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:45:47.834185Z","iopub.execute_input":"2022-05-09T18:45:47.834377Z","iopub.status.idle":"2022-05-09T18:45:47.841355Z","shell.execute_reply.started":"2022-05-09T18:45:47.834350Z","shell.execute_reply":"2022-05-09T18:45:47.840436Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nplt.figure(figsize=(12, 8))\nsns.heatmap(df.corr(), annot=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:45:47.843441Z","iopub.execute_input":"2022-05-09T18:45:47.843799Z","iopub.status.idle":"2022-05-09T18:45:49.391662Z","shell.execute_reply.started":"2022-05-09T18:45:47.843758Z","shell.execute_reply":"2022-05-09T18:45:49.391104Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"for i in df.columns:\n    plt.title(f'Distribution of feature {i}')\n    plt.style.use('fivethirtyeight')\n    df[i].plot(kind='hist')\n    plt.figure(figsize=(12, 8))","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:45:49.394441Z","iopub.execute_input":"2022-05-09T18:45:49.394764Z","iopub.status.idle":"2022-05-09T18:45:53.729252Z","shell.execute_reply.started":"2022-05-09T18:45:49.394729Z","shell.execute_reply":"2022-05-09T18:45:53.728434Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nplt.figure(figsize=(12, 8))\nsns.scatterplot(df['ambient'],df['pm'])","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:45:53.730494Z","iopub.execute_input":"2022-05-09T18:45:53.730802Z","iopub.status.idle":"2022-05-09T18:45:57.673897Z","shell.execute_reply.started":"2022-05-09T18:45:53.730764Z","shell.execute_reply":"2022-05-09T18:45:57.673383Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.scatterplot(df['coolant'],df['pm'])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:45:57.674767Z","iopub.execute_input":"2022-05-09T18:45:57.675874Z","iopub.status.idle":"2022-05-09T18:46:01.642246Z","shell.execute_reply.started":"2022-05-09T18:45:57.675818Z","shell.execute_reply":"2022-05-09T18:46:01.641428Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.scatterplot(df['u_q'],df['pm'])","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:46:01.644020Z","iopub.execute_input":"2022-05-09T18:46:01.644340Z","iopub.status.idle":"2022-05-09T18:46:05.691252Z","shell.execute_reply.started":"2022-05-09T18:46:01.644303Z","shell.execute_reply":"2022-05-09T18:46:05.690391Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.scatterplot(df['u_d'],df['pm'])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:46:05.692516Z","iopub.execute_input":"2022-05-09T18:46:05.692770Z","iopub.status.idle":"2022-05-09T18:46:09.676085Z","shell.execute_reply.started":"2022-05-09T18:46:05.692739Z","shell.execute_reply":"2022-05-09T18:46:09.675368Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.scatterplot(df['i_q'],df['pm'])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:46:09.677178Z","iopub.execute_input":"2022-05-09T18:46:09.677408Z","iopub.status.idle":"2022-05-09T18:46:13.627609Z","shell.execute_reply.started":"2022-05-09T18:46:09.677377Z","shell.execute_reply":"2022-05-09T18:46:13.627097Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.scatterplot(df['i_d'],df['pm'])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:46:13.628491Z","iopub.execute_input":"2022-05-09T18:46:13.628807Z","iopub.status.idle":"2022-05-09T18:46:17.654352Z","shell.execute_reply.started":"2022-05-09T18:46:13.628774Z","shell.execute_reply":"2022-05-09T18:46:17.653682Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.scatterplot(df['motor_speed'],df['pm'])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:46:17.655430Z","iopub.execute_input":"2022-05-09T18:46:17.655662Z","iopub.status.idle":"2022-05-09T18:46:21.677993Z","shell.execute_reply.started":"2022-05-09T18:46:17.655615Z","shell.execute_reply":"2022-05-09T18:46:21.675693Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#not important so we will drop it from the data frame\ndf.drop('profile_id', axis=1, inplace=True )","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:46:21.679134Z","iopub.execute_input":"2022-05-09T18:46:21.679569Z","iopub.status.idle":"2022-05-09T18:46:21.706193Z","shell.execute_reply.started":"2022-05-09T18:46:21.679536Z","shell.execute_reply":"2022-05-09T18:46:21.705461Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"x  = df.drop(['motor_speed'], axis=1)\ny = df['motor_speed']","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:46:21.707836Z","iopub.execute_input":"2022-05-09T18:46:21.708077Z","iopub.status.idle":"2022-05-09T18:46:21.741156Z","shell.execute_reply.started":"2022-05-09T18:46:21.708037Z","shell.execute_reply":"2022-05-09T18:46:21.740667Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:46:21.742114Z","iopub.execute_input":"2022-05-09T18:46:21.742401Z","iopub.status.idle":"2022-05-09T18:46:21.746361Z","shell.execute_reply.started":"2022-05-09T18:46:21.742372Z","shell.execute_reply":"2022-05-09T18:46:21.745965Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"x","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:46:21.747196Z","iopub.execute_input":"2022-05-09T18:46:21.747451Z","iopub.status.idle":"2022-05-09T18:46:21.772671Z","shell.execute_reply.started":"2022-05-09T18:46:21.747426Z","shell.execute_reply":"2022-05-09T18:46:21.771889Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score\n\nx_train, x_test,y_train,y_test=train_test_split(x,y,test_size=0.2, random_state=42)\n\ntraining=df.copy()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:46:21.773663Z","iopub.execute_input":"2022-05-09T18:46:21.774554Z","iopub.status.idle":"2022-05-09T18:46:21.996417Z","shell.execute_reply.started":"2022-05-09T18:46:21.774517Z","shell.execute_reply":"2022-05-09T18:46:21.995679Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"x_train","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:46:21.997906Z","iopub.execute_input":"2022-05-09T18:46:21.998132Z","iopub.status.idle":"2022-05-09T18:46:22.013532Z","shell.execute_reply.started":"2022-05-09T18:46:21.998102Z","shell.execute_reply":"2022-05-09T18:46:22.013122Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"x_test","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:46:22.014254Z","iopub.execute_input":"2022-05-09T18:46:22.014486Z","iopub.status.idle":"2022-05-09T18:46:22.040684Z","shell.execute_reply.started":"2022-05-09T18:46:22.014465Z","shell.execute_reply":"2022-05-09T18:46:22.040049Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"x_train_scaled = scale(x_train)\nx_test_scaled = scale(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:46:22.041728Z","iopub.execute_input":"2022-05-09T18:46:22.042272Z","iopub.status.idle":"2022-05-09T18:46:22.276141Z","shell.execute_reply.started":"2022-05-09T18:46:22.042223Z","shell.execute_reply":"2022-05-09T18:46:22.275015Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Define cross-validation folds\ncv = KFold(n_splits=10, shuffle=True, random_state=42)\nlin_reg = LinearRegression().fit(x_train_scaled, y_train)\n\n# Get R2 score\nr2 = lin_reg.score(x_train_scaled, y_train)\n\nlr_score = -1 * cross_val_score(lin_reg, \n                                 x_train_scaled, \n                                 y_train, \n                                 cv=cv, \n                                 scoring='neg_root_mean_squared_error')\nprint(lr_score)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:46:22.277376Z","iopub.execute_input":"2022-05-09T18:46:22.277619Z","iopub.status.idle":"2022-05-09T18:46:26.313116Z","shell.execute_reply.started":"2022-05-09T18:46:22.277588Z","shell.execute_reply":"2022-05-09T18:46:26.311679Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"lr_score_train = np.mean(lr_score)\nlr_score_train","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:46:26.314502Z","iopub.execute_input":"2022-05-09T18:46:26.314762Z","iopub.status.idle":"2022-05-09T18:46:26.320168Z","shell.execute_reply.started":"2022-05-09T18:46:26.314725Z","shell.execute_reply":"2022-05-09T18:46:26.319539Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#r2_score\nr2","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:46:26.330592Z","iopub.execute_input":"2022-05-09T18:46:26.331721Z","iopub.status.idle":"2022-05-09T18:46:26.338893Z","shell.execute_reply.started":"2022-05-09T18:46:26.331681Z","shell.execute_reply":"2022-05-09T18:46:26.338313Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#predict\ny_predicted = lin_reg.predict(x_test_scaled)\nlr_score_test = mean_squared_error(y_test, y_predicted, squared=False)\nlr_score_test","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:46:26.340390Z","iopub.execute_input":"2022-05-09T18:46:26.341440Z","iopub.status.idle":"2022-05-09T18:46:26.359783Z","shell.execute_reply.started":"2022-05-09T18:46:26.341407Z","shell.execute_reply":"2022-05-09T18:46:26.359177Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"#Lasso Regression (L1 regularization)\nlasso_reg = LassoCV().fit(x_train_scaled, y_train)\n\n\n# Get R2 score\nlasso_reg.score(x_train_scaled, y_train)\n\nlasso_scores = -1 * cross_val_score(lasso_reg, \n                                    x_train_scaled, \n                                    y_train, \n                                    cv=cv, \n                                    scoring='neg_root_mean_squared_error')\nprint(lasso_scores)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T18:46:26.361193Z","iopub.execute_input":"2022-05-09T18:46:26.362300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lasso_score_train = np.mean(lasso_scores)\nlasso_score_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict","metadata":{}},{"cell_type":"code","source":"y_predicted = lasso_reg.predict(x_test_scaled)\nlasso_score_test = mean_squared_error(y_test, y_predicted, squared=False)\nlasso_score_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ridge Regression (L2 regularization)","metadata":{}},{"cell_type":"code","source":"ridge_reg = RidgeCV().fit(x_train_scaled, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get R2 score\nridge_reg.score(x_train_scaled, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ridge_scores = -1 * cross_val_score(ridge_reg, \n                                    x_train_scaled, \n                                    y_train, \n                                    cv=cv, \n                                    scoring='neg_root_mean_squared_error')\nprint(ridge_scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ridge_score_train = np.mean(ridge_scores)\nprint(ridge_score_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict","metadata":{}},{"cell_type":"code","source":"\ny_predicted = ridge_reg.predict(x_test_scaled)\nridge_score_test = mean_squared_error(y_test, y_predicted, squared=False)\nridge_score_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualizing for Multiple Linear Regression y values\n\nimport seaborn as sns\nax1 = sns.distplot(y_train, hist=False, color=\"r\", label=\"Actual Value\")\nsns.distplot(y_test, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca = PCA()\nx_train_pc = pca.fit_transform(x_train_scaled)\n\npd.DataFrame(pca.components_.T).loc[:10, :]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca.explained_variance_ratio_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Linear Regression\nlin_reg = LinearRegression().fit(x_train_scaled, y_train)\nlr_score_train = -1 * cross_val_score(lin_reg, x_train_scaled, y_train, cv=cv, scoring='neg_root_mean_squared_error').mean()\nlr_score_test = mean_squared_error(y_test, lin_reg.predict(x_test_scaled), squared=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize linear regression instance\nlin_reg2 = LinearRegression()\n\n# Create empty list to store RMSE for each iteration\nrmse_list = []\n\n# Loop through different count of principal components for linear regression\nfor i in range(1, x_train_pc.shape[1]+1):\n    rmse_score = -1 * cross_val_score(lin_reg2, \n                                      x_train_pc[:,:i], # Use first k principal components\n                                      y_train, \n                                      cv=cv, \n                                      scoring='neg_root_mean_squared_error').mean()\n    rmse_list.append(rmse_score)\n    \n# Visual analysis - plot RMSE vs count of principal components used\nplt.plot(rmse_list, '-o')\nplt.xlabel('Number of principal components in regression')\nplt.ylabel('RMSE')\nplt.title('Quality')\nplt.xlim(xmin=-1);\nplt.xticks(np.arange(x_train_pc.shape[1]), np.arange(1, x_train_pc.shape[1]+1))\nplt.axhline(y=lr_score_train, color='g', linestyle='-');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visually determine optimal number of principal components\nbest_pc_num = 8\n\n# Train model with first 8 principal components\nlin_reg_pc = LinearRegression().fit(x_train_pc[:,:best_pc_num], y_train)\n\n# Get cross-validation RMSE (train set)\npcr_score_train = -1 * cross_val_score(lin_reg_pc, \n                                       x_train_pc[:,:best_pc_num], \n                                       y_train, \n                                       cv=cv, \n                                       scoring='neg_root_mean_squared_error').mean()\n\n# Train model on training set\nlin_reg_pc = LinearRegression().fit(x_train_pc[:,:best_pc_num], y_train)\n\n# Get first 8 principal components of test set\nx_test_pc = pca.transform(x_test_scaled)[:,:best_pc_num]\n\n# Predict on test data\npreds = lin_reg_pc.predict(x_test_pc)\npcr_score_test = mean_squared_error(y_test, preds, squared=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pcr_score_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_metrics = np.array([round(lr_score_train,3), \n                          round(lasso_score_train,3), \n                          round(ridge_score_train,3), \n                          round(pcr_score_train,3)]) \ntrain_metrics = pd.DataFrame(train_metrics, columns=['RMSE (Train Set)'])\ntrain_metrics.index = ['Linear Regression', \n                       'Lasso Regression', \n                       'Ridge Regression', \n                       f'PCR ({best_pc_num} components)']\ntrain_metrics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_metrics = np.array([round(lr_score_test,3), \n                         round(lasso_score_test,3), \n                         round(ridge_score_test,3), \n                         round(pcr_score_test,3)]) \ntest_metrics = pd.DataFrame(test_metrics, columns=['RMSE (Test Set)'])\ntest_metrics.index = ['Linear Regression', \n                      'Lasso Regression', \n                      'Ridge Regression', \n                      f'PCR ({best_pc_num} components)']\ntest_metrics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualizing for Multiple Linear Regression y values\n\nimport seaborn as sns\nax1 = sns.distplot(y_train, hist=False, color=\"r\", label=\"Actual Value\")\nsns.distplot(y_test, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#lets try in different way","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Scaling the data\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nx_train_scaled = scaler.fit_transform(x_train)\nx_test_scaled = scaler.transform(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Training the dataset\nfrom sklearn.linear_model import  Ridge, Lasso, LinearRegression, SGDRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor,  AdaBoostRegressor, BaggingRegressor\nfrom xgboost import XGBRegressor, XGBRFRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model):\n    # Define Models Name\n    print('model: {}'.format(model))\n    ## fitting the model\n    model.fit(x_train_scaled,y_train)\n    ## predicting the value\n    y_pred = model.predict(x_test_scaled)\n    print('R2 score',r2_score(y_test,y_pred))\n    print('MAE',mean_absolute_error(y_test,y_pred))\n    print('RMSE:{}'.format(np.sqrt(mean_squared_error(y_test,y_pred))))\n    plt.figure(figsize=(12, 8))\n    sns.distplot(y_test-y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nplt.figure(figsize=(12, 8))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(LinearRegression())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(Ridge())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(Lasso())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(DecisionTreeRegressor())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(KNeighborsRegressor())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(XGBRegressor())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from catboost import CatBoostRegressor\n\ncbr_model = CatBoostRegressor(n_estimators=200, \n                             loss_function='MAE',\n                             eval_metric='RMSE')\n\ncbr_model.fit(x_train, y_train)\n\ny_predict = cbr_model.predict(x_test)\nr2_score(y_test, y_predict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import MinMaxScaler\n\nct =  make_column_transformer((MinMaxScaler(),['u_q', 'coolant', 'stator_winding', 'u_d', 'stator_tooth', 'i_d', 'i_q',\n       'pm', 'stator_yoke', 'ambient', 'torque']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = df.drop(['motor_speed'], axis=1)\ny = df['motor_speed']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split,cross_val_score,cross_val_predict\nx_train , x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, \n                                                     random_state=42)\n\nct.fit(x_train)\n\nx_train_normal = ct.transform(x_train)\nx_test_normal = ct.transform(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ntf.random.set_seed(42)\n\n\n\n# Build the model (3 layers, 100, 10, 1 units)\nmodel_1 = tf.keras.Sequential([\n  tf.keras.layers.Dense(100),\n  tf.keras.layers.Dense(64),\n   tf.keras.layers.Dense(32),\n  tf.keras.layers.Dense(1)\n])\n\n# Compile the model\nmodel_1.compile(loss=tf.keras.losses.mae,\n                          optimizer=tf.keras.optimizers.Adam(),\n                          metrics=['mse'])\n\n# Fit the model for 200 epochs (same as insurance_model_2)\nhistory = model_1.fit(x_train_normal, y_train, epochs=10, verbose=100) \n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1_loss, model_1_mae = model_1.evaluate(x_test_normal, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Compare modelling results from non-normalized data and normalized data\nmodel_1_loss , model_1_mae","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check out our second model's architecture\nmodel_1.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}